{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import math\n",
    "from math import floor\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lkochiev/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['attributes', 'boxes_1024', 'boxes_512', 'img_to_first_box', 'img_to_first_rel', 'img_to_last_box', 'img_to_last_rel', 'labels', 'predicates', 'relationships', 'split']>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vg_sgg_dicts = h5py.File('GQA-with-attri.h5')\n",
    "vg_sgg_dicts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated SGG labels\n",
    "image_data = json.load(open('gqa_image_metadata.json'))\n",
    "vg_sgg_dicts = json.load(open('GQA-dicts.json'))\n",
    "vg_sgg = h5py.File('GQA.h5', 'r')\n",
    "\n",
    "# download from https://visualgenome.org\n",
    "# objects.json from https://visualgenome.org/static/data/dataset/objects_v1_2.json.zip\n",
    "# attributes.json from https://visualgenome.org/static/data/dataset/attributes.json.zip\n",
    "# attribute_synsets.json from https://visualgenome.org/static/data/dataset/attribute_synsets.json.zip\n",
    "original_objects = json.load(open(\"./gqa_objects.json\"))\n",
    "original_attributes = json.load(open(\"./gqa_attributes.json\"))\n",
    "\n",
    "original_attributes_haha = open(\"./gqa_attribute_list.txt\").read()\n",
    "original_attribute_synsets = {}\n",
    "original_attributes_haha = original_attributes_haha.split('\\n')\n",
    "for word in original_attributes_haha:\n",
    "    original_attribute_synsets[word] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE:Counting the number of atttributes for each objects\n",
    "we should use a threshold to select the maximum number of attributes \n",
    "for each objects for efficiency\n",
    "\"\"\"\n",
    "def count_num_attri_per_obj(all_attributes, MAX_NUM_ATT=20):\n",
    "    num_attr_count = [0]*MAX_NUM_ATT\n",
    "    for img in all_attributes:\n",
    "        img_annos = img['attributes']\n",
    "        for anno in img_annos:\n",
    "            if 'attributes' in anno:\n",
    "                len_attr = len(anno['attributes'])\n",
    "                if len_attr >= MAX_NUM_ATT-1:\n",
    "                    num_attr_count[MAX_NUM_ATT-1] += 1\n",
    "                else:\n",
    "                    num_attr_count[len_attr] += 1\n",
    "            else:\n",
    "                num_attr_count[0] += 1\n",
    "    return num_attr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: calculate the number of objects for each image\n",
    "\"\"\"\n",
    "def count_num_obj_per_img(original_objects, MAX_NUM_OBJ=50, print_multi_label=False):\n",
    "    num_obj_count = [0]*MAX_NUM_OBJ\n",
    "    for img in original_objects:\n",
    "        img_annos = img['objects']\n",
    "        len_obj = len(img_annos)\n",
    "        if len_obj >= MAX_NUM_OBJ-1:\n",
    "            num_obj_count[MAX_NUM_OBJ-1] += 1\n",
    "        else:\n",
    "            num_obj_count[len_obj] += 1\n",
    "        for anno in img_annos:\n",
    "            if len(anno['names']) != 1 and print_multi_label:\n",
    "                print('obj_id: {} with {}'.format(anno['object_id'], anno['names']))\n",
    "    return num_obj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: Counting the number of each attribute categories\n",
    "it can be used to select the most frequent attributes in the dataset\n",
    "we should also use the attribute_synsets to merge the similar categories\n",
    "Return a dictionary\n",
    "\"\"\"\n",
    "def count_attributes(all_attributes):\n",
    "    attribute_counts = {}\n",
    "    for img in all_attributes:\n",
    "        img_annos = img['attributes']\n",
    "        for anno in img_annos:\n",
    "            if 'attributes' in anno:\n",
    "                for item in anno['attributes']:\n",
    "                    item = ' '.join(item.lower().split())\n",
    "                    if item in attribute_counts:\n",
    "                        attribute_counts[item] = attribute_counts[item] + 1\n",
    "                    else:\n",
    "                        attribute_counts[item] = 1\n",
    "    return attribute_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_to_index(attri_name, attri_to_idx, cared_mapping):\n",
    "    original_name = attri_name\n",
    "    attri_name = ' '.join(attri_name.lower().split())\n",
    "    if attri_name in cared_mapping:\n",
    "        attri_name = cared_mapping[attri_name]\n",
    "    if attri_name in attri_to_idx:\n",
    "        return attri_to_idx[attri_name]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE:Counting the number of atttributes for each objects\n",
    "we should use a threshold to select the maximum number of attributes \n",
    "for each objects for efficiency\n",
    "\"\"\"\n",
    "def count_num_selected_attri_per_obj(all_attributes, attribute_to_idx, cared_mapping, MAX_NUM_ATT=20):\n",
    "    num_attr_count = [0]*MAX_NUM_ATT\n",
    "    for img in all_attributes:\n",
    "        img_annos = img['attributes']\n",
    "        for anno in img_annos:\n",
    "            if 'attributes' in anno:\n",
    "                selected_attries = []\n",
    "                for att_name in anno['attributes']:\n",
    "                    idx = attribute_to_index(att_name, attribute_to_idx, cared_mapping)\n",
    "                    if idx != 0:\n",
    "                        selected_attries.append(idx)\n",
    "                selected_attries = list(set(selected_attries))\n",
    "                len_attr = len(selected_attries)\n",
    "                if len_attr >= MAX_NUM_ATT-1:\n",
    "                    num_attr_count[MAX_NUM_ATT-1] += 1\n",
    "                else:\n",
    "                    num_attr_count[len_attr] += 1\n",
    "            else:\n",
    "                num_attr_count[0] += 1\n",
    "    return num_attr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: process attribute_synsets\n",
    "\"\"\"\n",
    "def processing_attribute_synsets(attribute_synsets, attributes_count):\n",
    "    attribute_mapping = {}\n",
    "    type_counting = {}\n",
    "    num_counting = {}\n",
    "    for key, val in attribute_synsets.items():\n",
    "        val_split = val.split('.')\n",
    "#         if len(val_split) != 3:\n",
    "#             print('--------------------------------')\n",
    "#             print('old_val: ', key, val)\n",
    "#             val = '_'.join(val_split[:-2]) + '.' + val_split[-2] + '.' + val_split[-1]\n",
    "#             print('new_val: ', key, val)\n",
    "#             print('--------------------------------')\n",
    "        key_root, key_type, key_num = val, 0, 0\n",
    "        if key in attributes_count:\n",
    "            key_count = attributes_count[key]\n",
    "        else:\n",
    "            key_count = 0\n",
    "        attribute_mapping[key] = {'key_root' : key_root, 'key_type' : 0, 'key_num' : 1, 'key_count' : 1}\n",
    "        if key_type in type_counting:\n",
    "            type_counting[key_type] = type_counting[key_type] + 1\n",
    "        else:\n",
    "            type_counting[key_type] = 1\n",
    "        if key_num in num_counting:\n",
    "            num_counting[key_num] = num_counting[key_num] + 1\n",
    "        else:\n",
    "            num_counting[key_num] = 1\n",
    "    return attribute_mapping, type_counting, num_counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge synset attribute based on attribute_synsets\n",
    "NOTE that, the attribute is not clean, especially those infrequent attribute\n",
    "so we do the following steps\n",
    "Step 1: select most frequent attribute (because they tend to be more clean and general)\n",
    "Step 2: only merge those key_root synset pair both occoured in select frequency list\n",
    "Step 2 Explain: when key not in list but root in, these keys can be very noise, so we skip them\n",
    "Step 3: padding new attributes to reach TOPK based on the number of merged synsets\n",
    "\n",
    "So what we want to make sure is, there is no synsets in selected attributes\n",
    "\"\"\"\n",
    "def merge_synset_attribute(mapping_dict, attribute_counts_list, TOPK=200):\n",
    "    selected_attributes = attribute_counts_list[:TOPK]\n",
    "    selected_attributes = [item[0] for item in selected_attributes]\n",
    "    cared_mapping = {}\n",
    "    for key, info in mapping_dict.items():\n",
    "        if (key in selected_attributes) and (info['key_root'] in selected_attributes) and (key != info['key_root']):\n",
    "            cared_mapping[key] = info['key_root']\n",
    "        elif (key in selected_attributes) and (info['key_root'] not in selected_attributes):\n",
    "            # key in, root not\n",
    "            continue\n",
    "        elif (key not in selected_attributes) and (info['key_root'] in selected_attributes):\n",
    "            # IMPORTANT!\n",
    "            # It't not clean, too dirty\n",
    "            # we don't merge these key\n",
    "            continue\n",
    "            #key_not_root_in[key] = info['key_root']\n",
    "        elif (key not in selected_attributes) and (info['key_root'] not in selected_attributes):\n",
    "            # both not in\n",
    "            continue\n",
    "        else:\n",
    "            # key == root, and in dict\n",
    "            continue\n",
    "    # eventually selected attributes\n",
    "    purged_attributes = attribute_counts_list[:TOPK+len(cared_mapping)]\n",
    "    purged_attributes = [item[0] for item in purged_attributes]\n",
    "    for removed_key in list(cared_mapping.keys()):\n",
    "        purged_attributes.remove(removed_key)\n",
    "    # in case we missing some\n",
    "    assert len(purged_attributes) == TOPK\n",
    "    selected_attributes = purged_attributes + list(cared_mapping.keys())\n",
    "    return cared_mapping, purged_attributes, selected_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "add attribute_count, idx_to_attribute, attribute_to_idx\n",
    "to vg_sgg_dicts\n",
    "\"\"\"\n",
    "def add_attribute_to_json(purged_atts, vg_sgg_dicts, cared_mapping, all_attribute_counts):\n",
    "    # construct attribute_count\n",
    "    attribute_count = {}\n",
    "    for att in purged_atts:\n",
    "        attribute_count[att] = all_attribute_counts[att]\n",
    "    for key, val in cared_mapping.items():\n",
    "        attribute_count[val] = all_attribute_counts[val] + all_attribute_counts[key]\n",
    "    vg_sgg_dicts['attribute_count'] = attribute_count\n",
    "    \n",
    "    # construct idx_to_attribute and attribute_to_idx\n",
    "    idx_to_attribute = {}\n",
    "    attribute_to_idx = {}\n",
    "    for i, att in enumerate(purged_atts):\n",
    "        idx_to_attribute[str(i+1)] = att\n",
    "        attribute_to_idx[att] = i+1\n",
    "    vg_sgg_dicts['idx_to_attribute'] = idx_to_attribute\n",
    "    vg_sgg_dicts['attribute_to_idx'] = attribute_to_idx\n",
    "    return vg_sgg_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_info(image_data, all_attributes):\n",
    "    image_info = []\n",
    "    attri_info = []\n",
    "    corrupted_ims = [] #['1592', '1722', '4616', '4617']\n",
    "    for item, att_item in tqdm(zip(image_data, all_attributes)):\n",
    "        if str(item['image_id']) not in corrupted_ims:\n",
    "#             assert item['image_id'] == att_item['image_id']\n",
    "#             if not item['image_id'] == att_item['image_id']:\n",
    "            image_info.append(item)\n",
    "            attri_info.append(att_item['attributes'])\n",
    "    return image_info, attri_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_box(region, org_h, org_w, im_long_size):\n",
    "    x = region['x']\n",
    "    y = region['y']\n",
    "    w = region['w']\n",
    "    h = region['h']\n",
    "    scale = float(im_long_size) / max(org_h, org_w)\n",
    "    image_size = im_long_size\n",
    "    # recall: x,y are 1-indexed\n",
    "    x, y = math.floor(scale*(region['x']-1)), math.floor(scale*(region['y']-1))\n",
    "    w, h = math.ceil(scale*region['w']), math.ceil(scale*region['h'])\n",
    "\n",
    "    # clamp to image\n",
    "    if x < 0: x = 0\n",
    "    if y < 0: y = 0\n",
    "\n",
    "    # box should be at least 2 by 2\n",
    "    if x > image_size - 2:\n",
    "        x = image_size - 2\n",
    "    if y > image_size - 2:\n",
    "        y = image_size - 2\n",
    "    if x + w >= image_size:\n",
    "        w = image_size - x\n",
    "    if y + h >= image_size:\n",
    "        h = image_size - y\n",
    "\n",
    "    # also convert to center-coord oriented\n",
    "    box = np.asarray([x+floor(w/2), y+floor(h/2), w, h], dtype=np.int32)\n",
    "    assert box[2] > 0  # width height should be positive numbers\n",
    "    assert box[3] > 0\n",
    "    \n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(boxes1, boxes2, to_move=1):\n",
    "    \"\"\"\n",
    "    boxes1 : numpy, [num_obj, 4] (x1,y1,x2,y2)\n",
    "    boxes2 : numpy, [num_obj, 4] (x1,y1,x2,y2)\n",
    "    \"\"\"\n",
    "    #print('boxes1: ', boxes1.shape)\n",
    "    #print('boxes2: ', boxes2.shape)\n",
    "    num_box1 = boxes1.shape[0]\n",
    "    num_box2 = boxes2.shape[0]\n",
    "    lt = np.maximum(boxes1.reshape([num_box1, 1, -1])[:,:,:2], boxes2.reshape([1, num_box2, -1])[:,:,:2]) # [N,M,2]\n",
    "    rb = np.minimum(boxes1.reshape([num_box1, 1, -1])[:,:,2:], boxes2.reshape([1, num_box2, -1])[:,:,2:]) # [N,M,2]\n",
    "\n",
    "    wh = (rb - lt + to_move).clip(min=0)  # [N,M,2]\n",
    "    inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n",
    "\n",
    "    lb = np.minimum(boxes1.reshape([num_box1, 1, -1])[:,:,:2], boxes2.reshape([1, num_box2, -1])[:,:,:2]) # [N,M,2]\n",
    "    rt = np.maximum(boxes1.reshape([num_box1, 1, -1])[:,:,2:], boxes2.reshape([1, num_box2, -1])[:,:,2:]) # [N,M,2]\n",
    "    wh = (rt - lb + to_move).clip(min=0)\n",
    "    outer = wh[:, :, 0] * wh[:, :, 1] + 1e-9  # [N,M]\n",
    "    return inter/outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_vg_sgg_h5py(vg_sgg, attributes, name='GQA-with-attri.h5'):\n",
    "    vg_sgg_with_attri = h5py.File(name, 'w')\n",
    "    # copy from original vg_sgg\n",
    "    for key in list(vg_sgg.keys()):\n",
    "        vg_sgg_with_attri.create_dataset(key, data=vg_sgg[key][:])\n",
    "    # add attributes\n",
    "    vg_sgg_with_attri.create_dataset('attributes', data=attributes)\n",
    "    vg_sgg_with_attri.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85509it [00:00, 1959893.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# MAIN \n",
    "\"\"\"\n",
    "various counting methods\n",
    "\"\"\"\n",
    "num_attr_count = count_num_attri_per_obj(original_attributes, 20)\n",
    "num_obj_count = count_num_obj_per_img(original_objects, MAX_NUM_OBJ=300)\n",
    "attribute_counts = count_attributes(original_attributes)\n",
    "\n",
    "\"\"\"\n",
    "select most frequent attribute by threshold\n",
    "\"\"\"\n",
    "# get sorted attribute list\n",
    "attribute_counts_list = [(key, val) for key, val in attribute_counts.items()]\n",
    "attribute_counts_list.sort(key=lambda v:v[1], reverse=True)\n",
    "# merge synset words\n",
    "mapping_dict, type_count, num_count = processing_attribute_synsets(original_attribute_synsets, attribute_counts)\n",
    "cared_mapping, purged_atts, selected_atts = merge_synset_attribute(mapping_dict, attribute_counts_list, TOPK=200)\n",
    "vg_sgg_dicts = add_attribute_to_json(purged_atts, vg_sgg_dicts, cared_mapping, attribute_counts)\n",
    "# save vg_sgg_dicts_with_attri.json\n",
    "with open('GQA-dicts-with-attri.json', 'w') as outfile:  \n",
    "    json.dump(vg_sgg_dicts, outfile)\n",
    "\n",
    "vg_sgg_dicts = json.load(open('GQA-dicts-with-attri.json'))\n",
    "idx_to_attribute = vg_sgg_dicts['idx_to_attribute']\n",
    "attribute_to_idx = vg_sgg_dicts['attribute_to_idx']\n",
    "\n",
    "# \"\"\"\n",
    "# assign attributes to each bounding box\n",
    "# \"\"\"\n",
    "image_info, attri_info = get_image_info(image_data, original_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "assign attribute annotation to each objects\n",
    "\"\"\"\n",
    "USE_BOX_SIZE = 1024\n",
    "\n",
    "def get_xyxy_boxes(img_atts, img_info, img_ind):\n",
    "    box_list = []\n",
    "    for item in img_atts:\n",
    "        x = item['x']\n",
    "        y = item['y']\n",
    "        w = item['w']\n",
    "        h = item['h']\n",
    "        scale = float(USE_BOX_SIZE) / max(img_info['height'], img_info['width'])\n",
    "        image_size = USE_BOX_SIZE\n",
    "        # recall: x,y are 1-indexed\n",
    "        x, y = math.floor(scale*(item['x']-1)), math.floor(scale*(item['y']-1))\n",
    "        w, h = math.ceil(scale*item['w']), math.ceil(scale*item['h'])\n",
    "\n",
    "        # clamp to image\n",
    "        if x < 0: x = 0\n",
    "        if y < 0: y = 0\n",
    "\n",
    "        # box should be at least 2 by 2\n",
    "        if x > image_size - 2:\n",
    "            x = image_size - 2\n",
    "        if y > image_size - 2:\n",
    "            y = image_size - 2\n",
    "        if x + w >= image_size:\n",
    "            w = image_size - x\n",
    "        if y + h >= image_size:\n",
    "            h = image_size - y\n",
    "\n",
    "        # also convert to center-coord oriented\n",
    "        box = np.asarray([x+floor(w/2), y+floor(h/2), w, h], dtype=np.int32)\n",
    "        \n",
    "        if box[2] > 0 and box[3] > 0:\n",
    "            box_list.append(box)\n",
    "        else: \n",
    "            continue\n",
    "    \n",
    "    box_list = np.vstack(box_list)\n",
    "    box_list[:, :2] = box_list[:, :2] - box_list[:, 2:] / 2\n",
    "    box_list[:, 2:] = box_list[:, :2] + box_list[:, 2:]\n",
    "    return box_list\n",
    "    \n",
    "def create_attributes_per_obj(vg_sgg, attri_info, image_info, attri_to_idx, cared_mapping, MAX_NUM_ATT=10, iou_thres=0.85):\n",
    "    num_objs = vg_sgg['labels'].shape[0]\n",
    "    num_imgs = vg_sgg['split'].shape[0]\n",
    "    assert num_imgs == len(attri_info)\n",
    "    assert num_imgs == len(image_info)\n",
    "    obj_attributes = np.zeros((num_objs, MAX_NUM_ATT)).astype(np.int64)\n",
    "    \n",
    "    num_matched_box = 0\n",
    "    for img_idx in range(num_imgs):\n",
    "        ith_s = vg_sgg['img_to_first_box'][img_idx]\n",
    "        ith_e = vg_sgg['img_to_last_box'][img_idx]\n",
    "        img_atts = attri_info[img_idx]\n",
    "        img_info = image_info[img_idx]\n",
    "        if len(img_atts) == 0:\n",
    "            continue\n",
    "        try:\n",
    "            img_boxes = get_xyxy_boxes(img_atts, img_info, image_info[img_idx]['image_id'])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        for obj_idx in range(ith_s, ith_e+1):\n",
    "            obj_att_set = []\n",
    "            obj_box = vg_sgg['boxes_1024'][obj_idx].reshape(1, -1)\n",
    "            obj_box[:, :2] = obj_box[:, :2] - obj_box[:, 2:] / 2\n",
    "            obj_box[:, 2:] = obj_box[:, :2] + obj_box[:, 2:]\n",
    "            match_idxs = (bbox_iou(img_boxes, obj_box) > iou_thres).astype(np.int64).reshape(-1)\n",
    "            if float(match_idxs.sum()) > 0:\n",
    "                num_matched_box += 1\n",
    "            for match_idx in np.where(match_idxs)[0].tolist():\n",
    "                if 'attributes' in img_atts[match_idx]:\n",
    "                    for attri_name in img_atts[match_idx]['attributes']:\n",
    "                        att_idx = attribute_to_index(attri_name, attri_to_idx, cared_mapping)\n",
    "                        if att_idx != 0:\n",
    "                            obj_att_set.append(att_idx)\n",
    "            # remove duplicate\n",
    "            obj_att_set = list(set(obj_att_set))[:MAX_NUM_ATT]\n",
    "            for i, att_idx in enumerate(obj_att_set):\n",
    "                obj_attributes[obj_idx, i] = att_idx\n",
    "    return obj_attributes, num_matched_box\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "generate attribute for each image\n",
    "\"\"\"\n",
    "obj_attributes, num_matched_box = create_attributes_per_obj(vg_sgg, attri_info, image_info, attribute_to_idx, cared_mapping, MAX_NUM_ATT=10, iou_thres=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save to h5py\n",
    "\"\"\"\n",
    "create_new_vg_sgg_h5py(vg_sgg, obj_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTEï¼š visualize the generated attribute\n",
    "\"\"\"\n",
    "\n",
    "def draw_single_box(pic, box, color=(255,0,255,128)):\n",
    "    draw = ImageDraw.Draw(pic)\n",
    "    x1,y1,x2,y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "    draw.rectangle(((x1, y1), (x2, y2)), outline=color)\n",
    "    \n",
    "def draw_boxes(image_id, boxes):\n",
    "    pic = Image.open('//local-scratch/data/GQA/images/images/{}.jpg'.format(image_id))\n",
    "    \n",
    "    num_obj = boxes.shape[0]\n",
    "    for i in range(num_obj):\n",
    "        draw_single_box(pic, boxes[i])\n",
    "    return pic\n",
    "    \n",
    "def show_box_attributes(image_data, vg_sgg, obj_attributes, vg_sgg_dicts, img_idx=None):\n",
    "    idx_to_label = vg_sgg_dicts['idx_to_label']\n",
    "    idx_to_attribute = vg_sgg_dicts['idx_to_attribute']\n",
    "    if img_idx is None:\n",
    "        img_idx = random.randint(0,len(image_data)-1)\n",
    "    height, width = image_data[img_idx]['height'], image_data[img_idx]['width']\n",
    "    filename = '//local-scratch/data/GQA/images/images/{}.jpg'.format(str(image_data[img_idx]['image_id']))\n",
    "    pic = Image.open(filename)\n",
    "    ith_s = vg_sgg['img_to_first_box'][img_idx]\n",
    "    ith_e = vg_sgg['img_to_last_box'][img_idx]\n",
    "    obj_idx = random.randint(ith_s, ith_e)\n",
    "    box = vg_sgg['boxes_1024'][obj_idx]\n",
    "    label = vg_sgg['labels'][obj_idx]\n",
    "    attribute = obj_attributes[obj_idx]\n",
    "    box[:2] = box[:2] - box[2:] / 2\n",
    "    box[2:] = box[:2] + box[2:]\n",
    "    box = box.astype(np.float) / USE_BOX_SIZE * max(height, width)\n",
    "    draw_single_box(pic, box)\n",
    "    att_list = []\n",
    "    if attribute.sum() > 0:\n",
    "        for i in attribute.tolist():\n",
    "            if i>0:\n",
    "                att_list.append(idx_to_attribute[str(i)])\n",
    "        print('Index: {}, Path: {}'.format(img_idx, filename))\n",
    "        print('Label: {}'.format(idx_to_label[str(int(label))]))\n",
    "        print('Attribute: {}'.format(','.join(att_list)))\n",
    "        return pic\n",
    "    else:\n",
    "        # make sure we have attributes\n",
    "        return show_box_attributes(image_data, vg_sgg, obj_attributes, vg_sgg_dicts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_box_attributes(image_info, vg_sgg, obj_attributes, vg_sgg_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "see all boxes of an image, if there is something wrong\n",
    "\"\"\"\n",
    "def show_wrong_image(wrong_idx, vg_sgg, image_info):\n",
    "    ith_s = vg_sgg['img_to_first_box'][wrong_idx]\n",
    "    ith_e = vg_sgg['img_to_last_box'][wrong_idx]\n",
    "\n",
    "    wrong_boxes = vg_sgg['boxes_1024'][ith_s : ith_e+1]\n",
    "    wrong_boxes[:, :2] = wrong_boxes[:, :2] - wrong_boxes[:, 2:] / 2\n",
    "    wrong_boxes[:, 2:] = wrong_boxes[:, :2] + wrong_boxes[:, 2:]\n",
    "    wrong_boxes = wrong_boxes.astype(np.float) / USE_BOX_SIZE * max(image_info[wrong_idx]['height'], image_info[wrong_idx]['width'])\n",
    "    \n",
    "    return draw_boxes(image_info[wrong_idx]['image_id'], wrong_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wrong_image(123, vg_sgg, image_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
